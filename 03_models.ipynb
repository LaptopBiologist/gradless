{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# costs - Wrapping objective functions and data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of classes and functions to structuring models to be optimized.\n",
    "***\n",
    "The `GradientDescent` optimizer expects the cost function to be stored within a class with an ```evaluate()``` method, which takes a 1D numpy array of parameter values and returns a float. A generic class `Model` is provided to organize user-defined cost functions and data so they can be easily passed to the optimizer. \n",
    "\n",
    "Should this class prove insufficient in some circumstances, a description of the API expected by `GradientDescent` along with an abstract base class is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import hypothesis\n",
    "from hypothesis import given\n",
    "import hypothesis.strategies as st\n",
    "import hypothesis.extra.numpy as hypo_numpy\n",
    "from hypothesis import note\n",
    "from numpy.testing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-798e5450e2c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ModelBase(ABC):\n",
    "    \"\"\"A helper class that provides a standard means to create\n",
    "    classes to store models used by GradientDescent.\"\"\"\n",
    "    \n",
    "\n",
    "    RV=None\n",
    "    update_rvs=True\n",
    "    @abstractmethod     #Require that all cost functions have the .evaluate method\n",
    "    \n",
    "    def evaluate(self): pass\n",
    "\n",
    "    def sample_rvs(self):\n",
    "        \"\"\"This can be used to regenerate a random variable used by the cost function.\n",
    "        It may be desirable hold some random variables constant during gradient evaluations, for example\"\"\"\n",
    "        if self.RV is not None:\n",
    "            self.z=self.RV.rvs()\n",
    "\n",
    "#         raise NotImplementedError(\"Cost functions must included a boolean attribute 'update_rvs'\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "The base class `ModelBase` is relatively simple, consisting of two methods and two attributes\n",
    "\n",
    "The methods are\n",
    "1. ```.evaluate``` which must be defined in any particular cost function class written by the user\n",
    "2. ```.sample_rvs``` which is automatically included in the base class, and draws a random variable if a random variable generator is stored in the RV attribute\n",
    "\n",
    "The two attributes are\n",
    "1. ```RV``` which by default is ```None```, but may be used to store a function that can generate random variables that are used in the evaluation of the cost function (e.g. ```scipy.stats.norm.rvs```)\n",
    "2. ```update_rvs``` is a flag that tells the `SPSAGradient` class to update the random variable each time it evaluates the gradient. By default this is ```True```, though this will only have an effect if a random variable generator is included in the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Model(ModelBase):\n",
    "    \"\"\"A class for passing objective functions and data to the GradientDescent\n",
    "    optimizer \n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    cost - the objective function to be minimized\n",
    "    data - the data to which the model will be fit (optional)\n",
    "    RV - An object with a .rvs() method to generate random variables\n",
    "        for the cost function\n",
    "    update_rvs: True/False call RV.rvs() before each gradient evaluation\n",
    "    \"\"\"\n",
    "    def __init__(self, cost, data=None, RV=None, update_rvs=False):\n",
    "\n",
    "        self.cost=cost\n",
    "        self.data=data\n",
    "        self.RV=RV\n",
    "        if self.RV is not None:\n",
    "            self.z=self.sample_rvs()\n",
    "        else: self.z=None\n",
    "        \n",
    "        if RV is None:\n",
    "            self.update_rvs=False\n",
    "        else:\n",
    "            assert type(update_rvs) is bool\n",
    "            self.update_rvs=update_rvs\n",
    "    def evaluate(self, theta):\n",
    "        if self.data is None and self.RV is None:\n",
    "            return self.cost(theta)\n",
    "        if self.data is None and self.RV is not None:\n",
    "            return self.cost(theta, self.z)\n",
    "        if self.RV is None:\n",
    "            return self.cost(theta, self.data)\n",
    "        else:\n",
    "            return self.cost(theta, self.data, self.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "## Here's a simple cost function for tests without data\n",
    "\n",
    "def quadratic(x,):\n",
    "    return x**2\n",
    "\n",
    "## Here's a simple cost function for tests without data, but with RV\n",
    "\n",
    "def quadratic_rv(x,z):\n",
    "    return x**2\n",
    "\n",
    "### Here's simple cost function for tests with data\n",
    "def MSE(theta, data, ):\n",
    "    x,y=data['x'], data['y']\n",
    "    y_pred=theta[0]*x+theta[1]\n",
    "    return numpy.mean((y-y_pred)**2)\n",
    "\n",
    "### Here's simple cost function for tests with data, but with RV\n",
    "def MSE_rv(theta, data, z):\n",
    "    x,y=data['x'], data['y']\n",
    "    y_pred=theta[0]*x+theta[1]\n",
    "    return numpy.mean((y-y_pred)**2)\n",
    "\n",
    "### Here's some sample data\n",
    "x=scipy.stats.norm.rvs(0, 5, size=200)\n",
    "err=scipy.stats.norm.rvs(0, 2, size=200)\n",
    "slope=2\n",
    "intercept=5\n",
    "y=x*slope+intercept +err\n",
    "\n",
    "data={'x':x,\n",
    "     'y':y}\n",
    "\n",
    "### These are just tests about behavior, so we're looking\n",
    "### to make sure errors aren't raised, not for consist\n",
    "### Let's make sure we can construct the model\n",
    "\n",
    "def test_Model_construction(cost, data):\n",
    "    model=Model(cost,data)\n",
    "test_Model_construction(MSE, data)\n",
    "\n",
    "\n",
    "### Let's make sure evaluate correctly calls the cost function \n",
    "### in the four possible scenarios\n",
    "\n",
    "def test_Model_evaluate_call(cost_no_data_no_rv,\n",
    "                             cost_no_data_with_rv,\n",
    "                             cost_with_data_no_rv,\n",
    "                             cost_with_data_with_rv,\n",
    "                             data,\n",
    "                             RV):\n",
    "    \n",
    "    model_no_data_no_RV=Model(cost_no_data_no_rv)\n",
    "    model_no_data_with_RV=Model(cost_no_data_with_rv, RV=RV)\n",
    "    model_with_data_no_RV=Model(cost_with_data_no_rv, data)\n",
    "    model_with_data_with_RV=Model(cost_with_data_with_rv, data, RV=RV)\n",
    "    #call evaluate for each\n",
    "    test_param=5\n",
    "    model_no_data_no_RV.evaluate(test_param)\n",
    "    model_no_data_with_RV.evaluate(test_param)\n",
    "    test_param=[5,4]\n",
    "    model_with_data_no_RV.evaluate(test_param)\n",
    "    model_with_data_with_RV.evaluate(test_param)\n",
    "    \n",
    "test_Model_evaluate_call(quadratic, quadratic_rv,MSE, MSE_rv,data, scipy.stats.norm(0,1) )    \n",
    "\n",
    "### Let's check to make sure evaluate returns the output of the cost function\n",
    "### This would likely fail if the cost was stochastic\n",
    "\n",
    "#Let's check without data\n",
    "def test_Model_without_data_evaluate_matches_cost(cost):\n",
    "    model=Model(cost)\n",
    "    test_param=5\n",
    "    assert (model.evaluate(test_param)==cost(test_param)), \".evaluate output does not match cost\"\n",
    "test_Model_without_data_evaluate_matches_cost(quadratic)    \n",
    "\n",
    "# let's check with data\n",
    "def test_Model_with_data_evaluate_matches_cost(cost, data):\n",
    "    model=Model(cost,data)\n",
    "    test_param=[5,2]\n",
    "    assert (model.evaluate(test_param)==cost(test_param,data)), \".evaluate output does not match cost\"\n",
    "test_Model_with_data_evaluate_matches_cost(MSE, data)\n",
    "\n",
    "### Let's make sure we can update the RV sample\n",
    "\n",
    "def test_Model_rvs(cost, data, rvs):\n",
    "    model=Model(cost,data,rvs)\n",
    "    z0=model.z\n",
    "    model.sample_rvs()\n",
    "    z1=model.z\n",
    "    try:\n",
    "        assert_array_equal(z0,z1)\n",
    "    except (AssertionError): \n",
    "        return\n",
    "    raise (AssertionError (\"Random variables should not match after update\"))\n",
    "test_Model_rvs(MSE_rv, data, scipy.stats.norm([0]*10, [1]*10))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's organized this data as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function that takes a vector of parameter values and data and uses these to returns a float. Note that it does not matter how the data is organized, so long as the function can interpret it internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "In general, though, it shouldn't be necessary to use the base class, as most simple cost functions can be wrapped in an instance of the `Model` class. The `Model` class can be used to wrapped both a cost function and data\n",
    "\n",
    "The only required argument is a user-defined cost function. If the model is to be fit to data, then the data--organized in a way that the cost function expects--should also passed to the class.\n",
    "\n",
    "The ```cost``` function should take three arguments:\n",
    "\n",
    "1. ```theta```: A 1-d numpy array of model parameters\n",
    "2. ```data```: (Optional) A variable storing the data\n",
    "3. ```z```: (Optional) The outcome of a random variable used to compute the objective function.\n",
    "\n",
    "The ```data``` may be organized however the ```cost``` expects, for example as dictionary, a list, or a numpy array.\n",
    "\n",
    "The two optional arguments taken by `Model` relate to a random variable that may be passed to the cost function:\n",
    "\n",
    "1. ```RV``` may be a passed a object with a ```.rvs()``` method that generates a random variable when called (e.g. a frozen scipy distribution such are ```scipy.stats.norm([0]*10,[1]*10)``` which can be used to generate 10 samples from a unit normal distribution.\n",
    "2. ```update_rvs``` stores a True/False value, telling the gradient approximation whether to regenerate the random variable after each gradient estimate.\n",
    "\n",
    "The current value the random variable drawn from ```RV``` is stored as the attribute ```z```.\n",
    "\n",
    "If these options are employed, the gradient approximation holds the random variable ```z``` constant during the forward and backward perturbations used to approximate the gradient. In general, I think it may be best to not use these options--my intution is that noise in the gradient due a simulator employed in the objective function ought to be left inside in the gradient (but I could be wrong). However, there are cases where it absolutely make sense to eliminate sources of randomness from the gradient evaluation, for example the Monte Carlo integration often employed to compute the objective function used in variational inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage\n",
    "\n",
    "Okay, let's try out an example, where we are interested in the mean-squared error of a simple linear regression.\n",
    "\n",
    "Now let's generate 200 data points from a simple linear relationship, with a slope of 2 and an intercept of 5:\n",
    "\n",
    "$$x \\sim normal(0, 5)$$\n",
    "\n",
    "$$\\epsilon \\sim normal(0,2)$$\n",
    "\n",
    "$$y=2x+5+\\epsilon$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scipy.stats.norm.rvs(0, 5, size=200)\n",
    "err=scipy.stats.norm.rvs(0, 2, size=200)\n",
    "slope=2\n",
    "intercept=5\n",
    "y=x*slope+intercept +err\n",
    "# pyplot.scatter(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's organized this data as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'x':x,\n",
    "     'y':y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function that takes a vector of parameter values and data and uses these to returns a float. Note that it does not matter how the data is organized, so long as the function can interpret it internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(theta, data):\n",
    "    x,y=data['x'], data['y']\n",
    "    y_pred=theta[0]*x+theta[1]\n",
    "    return numpy.mean((y-y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we'll wrap the cost function and the data in the `Model` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cost=Model(MSE, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we didn't pass any random variable generators, both ```update_rvs``` and ```RV``` remain at their default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"mse_cost.RV = {mse_cost.RV}\")\n",
    "print (f\"mse_cost.update_rvs = {mse_cost.update_rvs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the cost function on the data by passing a proposed parameter value to the ```.evaluate()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cost.evaluate([2,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could further use this to visualize the landscape of the objective function a grid of different combinations of (slope, intercept) parameters (the parameter value used to generate the data is marked with a red X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,Z=[],[],[]\n",
    "for slope in numpy.arange(-10, 10,.2):\n",
    "\n",
    "    for intercept in numpy.arange(-10, 10,.2):\n",
    "        Y.append(intercept)\n",
    "        X.append(slope)\n",
    "        Z.append(mse_cost.evaluate([slope,intercept]))\n",
    "sc=pyplot.scatter(X,Y, c=numpy.log(Z))\n",
    "pyplot.scatter(2, 5, marker='x',s=100, c='r')\n",
    "cbar=pyplot.colorbar(sc)\n",
    "cbar.set_label('log (MSE)', size=14)\n",
    "pyplot.ylabel('Intercept')\n",
    "pyplot.xlabel('Slope')\n",
    "pyplot.xlim(-10,10)\n",
    "pyplot.ylim(-10,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
