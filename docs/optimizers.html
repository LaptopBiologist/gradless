---

title: optimizers


keywords: fastai
sidebar: home_sidebar



nb_path: "01_optimizers.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_optimizers.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GradientDescent" class="doc_header"><code>class</code> <code>GradientDescent</code><a href="https://github.com/LaptopBiologist/gradless/tree/master/gradless/optimizers.py#L12" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GradientDescent</code>(<strong><code>x_0</code></strong>, <strong><code>cost</code></strong>, <strong><code>update</code></strong>, <strong><code>gradient</code></strong>=<em><code>&lt;gradless.gradient.SPSAGradient object at 0x7f8740510ef0&gt;</code></em>, <strong><code>param_stepsize</code></strong>=<em><code>1</code></em>, <strong><code>param_stepdecay</code></strong>=<em><code>0.4</code></em>, <strong><code>param_decay_offset</code></strong>=<em><code>0</code></em>, <strong><code>grad_stepsize</code></strong>=<em><code>1</code></em>, <strong><code>grad_stepdecay</code></strong>=<em><code>0.2</code></em>, <strong><code>seed</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-5-5c496cc2f8a1&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#export</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">class</span> GradientDescent<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>     def __init__(self,x_0, cost, update, gradient=SPSAGradient(), 
<span class="ansi-green-intense-fg ansi-bold">      4</span>                  param_stepsize<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> param_stepdecay<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">.4</span><span class="ansi-blue-fg">,</span> param_decay_offset<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>                  grad_stepsize<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> grad_stepdecay<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">.2</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">&lt;ipython-input-5-5c496cc2f8a1&gt;</span> in <span class="ansi-cyan-fg">GradientDescent</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#export</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">class</span> GradientDescent<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     def __init__(self,x_0, cost, update, gradient=SPSAGradient(), 
</span><span class="ansi-green-intense-fg ansi-bold">      4</span>                  param_stepsize<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> param_stepdecay<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">.4</span><span class="ansi-blue-fg">,</span> param_decay_offset<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>                  grad_stepsize<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> grad_stepdecay<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">.2</span><span class="ansi-blue-fg">,</span>

<span class="ansi-red-fg">NameError</span>: name &#39;SPSAGradient&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Parameter-initialization">Parameter initialization<a class="anchor-link" href="#Parameter-initialization"> </a></h3><p>There are two main sets of parameters that need to be chosen: parameters determining the size of the update step and parameters determining the size the of the step used to estimate the gradient.</p>
<p>It would be useful to have some functions for choosing these.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">initialize_param_step</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span><span class="n">gradient_reps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">t</span><span class="o">+=</span><span class="mf">1.</span>
    <span class="n">c_k</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">grad_step</span><span class="p">()</span>
    <span class="c1">### get the gradient</span>
    <span class="n">ghat</span><span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">gradient</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">cost</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">c_k</span><span class="p">,</span> <span class="n">gradient_reps</span><span class="o">=</span><span class="n">gradient_reps</span><span class="p">,</span> <span class="n">update_rvs</span><span class="o">=</span><span class="kc">True</span> <span class="p">)</span>

    <span class="c1">### determine the proposed step</span>
    <span class="n">a_k</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">param_step</span><span class="p">()</span>
    <span class="n">step</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">update</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ghat</span><span class="p">,</span> <span class="n">a_k</span> <span class="p">,</span><span class="n">opt</span><span class="o">.</span><span class="n">t</span><span class="p">)</span>
    <span class="n">current_cost</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">cost</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
        <span class="n">test_theta</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">theta</span><span class="o">-</span><span class="n">step</span><span class="o">/</span><span class="mf">2.</span><span class="o">**</span><span class="n">k</span>
        <span class="n">test_cost</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">cost</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_theta</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">a_k</span><span class="o">/</span><span class="mf">2.</span><span class="o">**</span><span class="n">k</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Adapting-initial-parameters">Adapting initial parameters<a class="anchor-link" href="#Adapting-initial-parameters"> </a></h3>
</div>
</div>
</div>
</div>
 

