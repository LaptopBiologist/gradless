---

title: gradient


keywords: fastai
sidebar: home_sidebar



nb_path: "04_gradient.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 04_gradient.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SPSAGradient</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_subsets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span><span class="o">=</span><span class="n">param_subsets</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subsets</span><span class="o">=</span><span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">param_subsets</span><span class="p">))</span>
        
    
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">c_k</span><span class="p">,</span> <span class="n">gradient_reps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="c1">#         assert len(theta)==len(self.)</span>
        <span class="c1">#If no subsets were defined, then now we&#39;ll define all model parameters as one set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">subsets</span><span class="o">=</span><span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span><span class="p">))</span>
        <span class="c1">#evaluate the gradient separately for different groups of parameters</span>
        <span class="n">grad_list</span><span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gradient_reps</span><span class="p">):</span>
            
            <span class="n">ghat</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">subsets</span><span class="p">:</span>
                <span class="n">param_filter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param_subsets</span><span class="o">==</span><span class="n">s</span>
                <span class="n">ghat</span><span class="o">+=</span><span class="bp">self</span><span class="o">.</span><span class="n">SPSA</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">ck</span><span class="p">,</span> <span class="n">param_filter</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="n">z</span><span class="p">)</span>
            <span class="n">grad_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ghat</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">gradient_reps</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">grad_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1">#We need to average</span>
            <span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">grad_list</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">SPSA</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">ck</span><span class="p">,</span> <span class="n">param_filter</span><span class="p">,</span><span class="n">z</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Inputs:</span>
<span class="sd">            cost - a function that takes model parameters and data as inputs</span>
<span class="sd">                    and returns a single float</span>
<span class="sd">            data - the data the model is being fit to</span>
<span class="sd">            theta - a set model parameters</span>
<span class="sd">            ck - the step size to be used during perturbation of the model parameters</span>

<span class="sd">            Outputs:</span>
<span class="sd">            An estimate of the gradient</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">#Draw the perturbation</span>

        <span class="n">delta</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span>
        <span class="c1">#hold delta constant for the parameters not under consideration</span>
        <span class="n">delta</span><span class="p">[</span><span class="o">~</span><span class="n">param_ind</span><span class="p">]</span><span class="o">=</span><span class="mf">0.</span>
        <span class="c1">#Perturb the parameters forwards and backwards</span>
        <span class="n">thetaplus</span><span class="o">=</span><span class="n">theta</span><span class="o">+</span><span class="n">ck</span><span class="o">*</span><span class="n">delta</span>
        <span class="n">thetaminus</span><span class="o">=</span><span class="n">theta</span><span class="o">-</span><span class="n">ck</span><span class="o">*</span><span class="n">delta</span>

        <span class="c1">#Evaluate the objective after the perturbations</span>
        <span class="n">yplus</span><span class="o">=</span><span class="n">cost</span><span class="p">(</span><span class="n">thetaplus</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="n">yminus</span><span class="o">=</span><span class="n">cost</span><span class="p">(</span><span class="n">thetaminus</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

        <span class="c1">#Compute the slope across the perturbation</span>

        <span class="n">ghat</span><span class="o">=</span><span class="p">(</span><span class="n">yplus</span><span class="o">-</span><span class="n">yminus</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">ck</span><span class="o">*</span><span class="n">delta</span><span class="p">)</span>

        <span class="n">ghat</span><span class="p">[</span><span class="o">~</span><span class="n">param_ind</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">return</span> <span class="n">ghat</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

